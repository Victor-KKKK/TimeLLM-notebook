{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UItzpXIgm2J",
    "outputId": "9f88d41b-816b-4845-95ec-8942047549c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Time-LLM'...\n",
      "remote: Enumerating objects: 186, done.\u001b[K\n",
      "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 186 (delta 72), reused 56 (delta 56), pack-reused 79 (from 1)\u001b[K\n",
      "Receiving objects: 100% (186/186), 1.08 MiB | 4.10 MiB/s, done.\n",
      "Resolving deltas: 100% (96/96), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/KimMeen/Time-LLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkhiSKcUilna",
    "outputId": "b9e6307a-8802-4d61-f959-8c5a37958a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m982.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, PySocks, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-5.2.0 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1NF7VEefXCmXuWNbnNe858WvQAkJ_7wuP\n",
      "From (redirected): https://drive.google.com/uc?id=1NF7VEefXCmXuWNbnNe858WvQAkJ_7wuP&confirm=t&uuid=31d7e8ba-792b-40d5-867f-aa0e60654bc7\n",
      "To: /workspace/dataset.zip\n",
      "100%|████████████████████████████████████████| 355M/355M [00:19<00:00, 17.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1NF7VEefXCmXuWNbnNe858WvQAkJ_7wuP -O dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]                \u001b[0m\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\n",
      "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]3m\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]m\u001b[33m\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1765 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4476 kB]\n",
      "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.8 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1246 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2984 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]33m\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4630 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3295 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1553 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
      "Fetched 40.6 MB in 4s (10.7 MB/s)[33m                         \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "143 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    }
   ],
   "source": [
    "!apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 143 not upgraded.\n",
      "Need to get 175 kB of archives.\n",
      "After this operation, 386 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
      "Fetched 175 kB in 0s (527 kB/s)[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unzip.\n",
      "(Reading database ... 20729 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up unzip (6.0-26ubuntu3.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install -y unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zRNo_MINj6XQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caution: filename not matched:  ./dataset\n"
     ]
    }
   ],
   "source": [
    "!unzip -q dataset.zip -d -y ./dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iAYKTZeNi2Vp"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /workspace/Time-LLM/dataset/ETT-small\n",
    "!cp /workspace/dataset/dataset/ETT-small/ETTh1.csv /content/Time-LLM/dataset/ETT-small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4Q_YSRcxioaH",
    "outputId": "834fc2c4-fe64-41a5-f7b4-af9f8521187b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.2 (from -r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting accelerate==0.28.0 (from -r /workspace/Time-LLM/requirements.txt (line 2))\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting einops==0.7.0 (from -r /workspace/Time-LLM/requirements.txt (line 3))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting matplotlib==3.7.0 (from -r /workspace/Time-LLM/requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting numpy==1.23.5 (from -r /workspace/Time-LLM/requirements.txt (line 5))\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting pandas==1.5.3 (from -r /workspace/Time-LLM/requirements.txt (line 6))\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scikit_learn==1.2.2 (from -r /workspace/Time-LLM/requirements.txt (line 7))\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.12.0 (from -r /workspace/Time-LLM/requirements.txt (line 8))\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m967.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.65.0 (from -r /workspace/Time-LLM/requirements.txt (line 9))\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft==0.4.0 (from -r /workspace/Time-LLM/requirements.txt (line 10))\n",
      "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting transformers==4.31.0 (from -r /workspace/Time-LLM/requirements.txt (line 11))\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting deepspeed==0.14.0 (from -r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece==0.2.0 (from -r /workspace/Time-LLM/requirements.txt (line 13))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (2023.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r /workspace/Time-LLM/requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r /workspace/Time-LLM/requirements.txt (line 2)) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r /workspace/Time-LLM/requirements.txt (line 2)) (6.0.1)\n",
      "Collecting huggingface-hub (from accelerate==0.28.0->-r /workspace/Time-LLM/requirements.txt (line 2))\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate==0.28.0->-r /workspace/Time-LLM/requirements.txt (line 2))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4))\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4))\n",
      "  Downloading fonttools-4.58.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4))\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4)) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4)) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas==1.5.3->-r /workspace/Time-LLM/requirements.txt (line 6))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit_learn==1.2.2->-r /workspace/Time-LLM/requirements.txt (line 7))\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit_learn==1.2.2->-r /workspace/Time-LLM/requirements.txt (line 7))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11))\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11)) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11))\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting hjson (from deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting ninja (from deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting py-cpuinfo (from deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pydantic (from deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pynvml (from deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting fsspec (from torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1))\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub->accelerate==0.28.0->-r /workspace/Time-LLM/requirements.txt (line 2))\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r /workspace/Time-LLM/requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (2.1.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->deepspeed==0.14.0->-r /workspace/Time-LLM/requirements.txt (line 12))\n",
      "  Using cached nvidia_ml_py-12.575.51-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r /workspace/Time-LLM/requirements.txt (line 11)) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->-r /workspace/Time-LLM/requirements.txt (line 1)) (1.3.0)\n",
      "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.2/444.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_ml_py-12.575.51-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400399 sha256=8e18be0a3021ea0a67d52b6d051f811efc9f28e6912810be7251f2af7e623db3\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: tokenizers, sentencepiece, pytz, py-cpuinfo, nvidia-ml-py, hjson, typing-extensions, triton, tqdm, threadpoolctl, safetensors, regex, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, kiwisolver, joblib, hf-xet, fsspec, fonttools, einops, cycler, annotated-types, typing-inspection, scipy, pydantic-core, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, contourpy, transformers, scikit_learn, pydantic, nvidia-cusolver-cu12, matplotlib, torch, deepspeed, accelerate, peft\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.2.2 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.28.0 annotated-types-0.7.0 contourpy-1.3.2 cycler-0.12.1 deepspeed-0.14.0 einops-0.7.0 fonttools-4.58.2 fsspec-2025.5.1 hf-xet-1.1.3 hjson-3.1.0 huggingface-hub-0.33.0 joblib-1.5.1 kiwisolver-1.4.8 matplotlib-3.7.0 ninja-1.11.1.4 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.575.51 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 peft-0.4.0 py-cpuinfo-9.0.0 pydantic-2.11.5 pydantic-core-2.33.2 pynvml-12.0.0 pytz-2025.2 regex-2024.11.6 safetensors-0.5.3 scikit_learn-1.2.2 scipy-1.12.0 sentencepiece-0.2.0 threadpoolctl-3.6.0 tokenizers-0.13.3 torch-2.2.2 tqdm-4.65.0 transformers-4.31.0 triton-2.2.0 typing-extensions-4.14.0 typing-inspection-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
      "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.11.5)\n",
      "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed) (12.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.65.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.4.1)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pynvml->deepspeed) (12.575.51)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /workspace/Time-LLM/requirements.txt\n",
    "!pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-25.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vi7fEyBqk-wp",
    "outputId": "b23d017c-4e02-47f1-fa59-0fb1364ee24a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.38.2 in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.38.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "id": "JVBJpRk4msND",
    "outputId": "3280c3ac-c9f0-4ddd-82d7-dc81ba202e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.4\n",
      "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping jax as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping jaxlib as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.4\n",
    "!pip uninstall -y jax jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "byzYiy7jnS3T"
   },
   "outputs": [],
   "source": [
    "ds_config = \"\"\"\n",
    "{\n",
    "  \"train_batch_size\": 8,\n",
    "  \"fp16\": {\n",
    "    \"enabled\": true\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": 2,\n",
    "    \"offload_optimizer\": {\n",
    "      \"device\": \"cpu\"\n",
    "    },\n",
    "    \"allgather_partitions\": true,\n",
    "    \"allgather_bucket_size\": 200000000,\n",
    "    \"overlap_comm\": true,\n",
    "    \"reduce_scatter\": true,\n",
    "    \"reduce_bucket_size\": 200000000\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"ds_config_zero2.json\", \"w\") as f:\n",
    "    f.write(ds_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.9ubuntu3).\n",
      "build-essential set to manually installed.\n",
      "The following additional packages will be installed:\n",
      "  autoconf automake autotools-dev file gfortran gfortran-11 ibverbs-providers\n",
      "  javascript-common libcaf-openmpi-3 libcoarrays-dev libcoarrays-openmpi-dev\n",
      "  libevent-2.1-7 libevent-core-2.1-7 libevent-dev libevent-extra-2.1-7\n",
      "  libevent-openssl-2.1-7 libevent-pthreads-2.1-7 libfabric1 libgfortran-11-dev\n",
      "  libgfortran5 libhwloc-dev libhwloc-plugins libhwloc15 libibverbs-dev\n",
      "  libibverbs1 libjs-jquery libjs-jquery-ui libltdl-dev libltdl7 libmagic-mgc\n",
      "  libmagic1 libnl-3-200 libnl-3-dev libnl-route-3-200 libnl-route-3-dev\n",
      "  libnuma-dev libnuma1 libopenmpi3 libpmix-dev libpmix2 libpsm-infinipath1\n",
      "  libpsm2-2 librdmacm1 libsigsegv2 libtool libucx0 libxnvctrl0 m4\n",
      "  ocl-icd-libopencl1 openmpi-common\n",
      "Suggested packages:\n",
      "  autoconf-archive gnu-standards autoconf-doc gettext gfortran-multilib\n",
      "  gfortran-doc gfortran-11-multilib gfortran-11-doc libhwloc-contrib-plugins\n",
      "  libjs-jquery-ui-docs libtool-doc openmpi-doc gcj-jdk m4-doc opencl-icd\n",
      "The following NEW packages will be installed:\n",
      "  autoconf automake autotools-dev file gfortran gfortran-11 ibverbs-providers\n",
      "  javascript-common libcaf-openmpi-3 libcoarrays-dev libcoarrays-openmpi-dev\n",
      "  libevent-2.1-7 libevent-core-2.1-7 libevent-dev libevent-extra-2.1-7\n",
      "  libevent-openssl-2.1-7 libevent-pthreads-2.1-7 libfabric1 libgfortran-11-dev\n",
      "  libgfortran5 libhwloc-dev libhwloc-plugins libhwloc15 libibverbs-dev\n",
      "  libibverbs1 libjs-jquery libjs-jquery-ui libltdl-dev libltdl7 libmagic-mgc\n",
      "  libmagic1 libnl-3-200 libnl-3-dev libnl-route-3-200 libnl-route-3-dev\n",
      "  libnuma-dev libnuma1 libopenmpi-dev libopenmpi3 libpmix-dev libpmix2\n",
      "  libpsm-infinipath1 libpsm2-2 librdmacm1 libsigsegv2 libtool libucx0\n",
      "  libxnvctrl0 m4 ocl-icd-libopencl1 openmpi-bin openmpi-common\n",
      "0 upgraded, 52 newly installed, 0 to remove and 143 not upgraded.\n",
      "Need to get 25.7 MB of archives.\n",
      "After this operation, 107 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmagic-mgc amd64 1:5.41-3ubuntu0.1 [257 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmagic1 amd64 1:5.41-3ubuntu0.1 [87.2 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 file amd64 1:5.41-3ubuntu0.1 [21.5 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnuma1 amd64 2.0.14-3ubuntu2 [22.5 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsigsegv2 amd64 2.13-1ubuntu3 [14.6 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 m4 amd64 1.4.18-5ubuntu2 [199 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 autoconf all 2.71-2 [338 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 autotools-dev all 20220109.1 [44.9 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 automake all 1:1.16.5-1.3 [558 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgfortran5 amd64 12.3.0-1ubuntu1~22.04 [879 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgfortran-11-dev amd64 11.4.0-1ubuntu1~22.04 [842 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gfortran-11 amd64 11.4.0-1ubuntu1~22.04 [11.2 MB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 gfortran amd64 4:11.2.0-1ubuntu1 [1182 B]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-3-200 amd64 3.5.0-0.1 [59.1 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-route-3-200 amd64 3.5.0-0.1 [180 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibverbs1 amd64 39.0-1 [69.3 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 ibverbs-providers amd64 39.0-1 [341 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5936 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevent-core-2.1-7 amd64 2.1.12-stable-1build3 [93.9 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevent-pthreads-2.1-7 amd64 2.1.12-stable-1build3 [7642 B]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpsm-infinipath1 amd64 3.3+20.604758e7-6.1 [170 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpsm2-2 amd64 11.2.185-1 [182 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 librdmacm1 amd64 39.0-1 [71.2 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfabric1 amd64 1.11.0-3 [558 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libhwloc15 amd64 2.7.0-2ubuntu1 [159 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ocl-icd-libopencl1 amd64 2.2.14-3 [39.1 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libhwloc-plugins amd64 2.7.0-2ubuntu1 [15.6 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpmix2 amd64 4.1.2-2ubuntu1 [604 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libucx0 amd64 1.12.1~rc2-1 [891 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenmpi3 amd64 4.1.2-2ubuntu1 [2594 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcaf-openmpi-3 amd64 2.9.2-3 [36.5 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcoarrays-dev amd64 2.9.2-3 [40.5 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 openmpi-common all 4.1.2-2ubuntu1 [162 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 openmpi-bin amd64 4.1.2-2ubuntu1 [116 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcoarrays-openmpi-dev amd64 2.9.2-3 [452 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevent-2.1-7 amd64 2.1.12-stable-1build3 [148 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevent-extra-2.1-7 amd64 2.1.12-stable-1build3 [65.4 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevent-openssl-2.1-7 amd64 2.1.12-stable-1build3 [15.8 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevent-dev amd64 2.1.12-stable-1build3 [278 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-jquery all 3.6.0+dfsg+~3.5.13-1 [321 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-jquery-ui all 1.13.1+dfsg-1 [253 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libltdl7 amd64 2.4.6-15build2 [39.6 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 libltdl-dev amd64 2.4.6-15build2 [169 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-3-dev amd64 3.5.0-0.1 [101 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-route-3-dev amd64 3.5.0-0.1 [202 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnuma-dev amd64 2.0.14-3ubuntu2 [35.9 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libhwloc-dev amd64 2.7.0-2ubuntu1 [256 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpmix-dev amd64 4.1.2-2ubuntu1 [805 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtool all 2.4.6-15build2 [164 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibverbs-dev amd64 39.0-1 [628 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenmpi-dev amd64 4.1.2-2ubuntu1 [867 kB]\n",
      "Get:52 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  libxnvctrl0 575.57.08-0ubuntu1 [11.5 kB]\n",
      "Fetched 25.7 MB in 1s (17.9 MB/s)         \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libmagic-mgc.\n",
      "(Reading database ... 20747 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libmagic-mgc_1%3a5.41-3ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libmagic-mgc (1:5.41-3ubuntu0.1) ...\n",
      "Selecting previously unselected package libmagic1:amd64.\n",
      "Preparing to unpack .../01-libmagic1_1%3a5.41-3ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  1%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libmagic1:amd64 (1:5.41-3ubuntu0.1) ...\n",
      "Selecting previously unselected package file.\n",
      "Preparing to unpack .../02-file_1%3a5.41-3ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking file (1:5.41-3ubuntu0.1) ...\n",
      "Selecting previously unselected package libnuma1:amd64.\n",
      "Preparing to unpack .../03-libnuma1_2.0.14-3ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libnuma1:amd64 (2.0.14-3ubuntu2) ...\n",
      "Selecting previously unselected package libsigsegv2:amd64.\n",
      "Preparing to unpack .../04-libsigsegv2_2.13-1ubuntu3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libsigsegv2:amd64 (2.13-1ubuntu3) ...\n",
      "Selecting previously unselected package m4.\n",
      "Preparing to unpack .../05-m4_1.4.18-5ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking m4 (1.4.18-5ubuntu2) ...\n",
      "Selecting previously unselected package autoconf.\n",
      "Preparing to unpack .../06-autoconf_2.71-2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking autoconf (2.71-2) ...\n",
      "Selecting previously unselected package autotools-dev.\n",
      "Preparing to unpack .../07-autotools-dev_20220109.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking autotools-dev (20220109.1) ...\n",
      "Selecting previously unselected package automake.\n",
      "Preparing to unpack .../08-automake_1%3a1.16.5-1.3_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking automake (1:1.16.5-1.3) ...\n",
      "Selecting previously unselected package libgfortran5:amd64.\n",
      "Preparing to unpack .../09-libgfortran5_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking libgfortran5:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package libgfortran-11-dev:amd64.\n",
      "Preparing to unpack .../10-libgfortran-11-dev_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking libgfortran-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package gfortran-11.\n",
      "Preparing to unpack .../11-gfortran-11_11.4.0-1ubuntu1~22.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking gfortran-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "Selecting previously unselected package gfortran.\n",
      "Preparing to unpack .../12-gfortran_4%3a11.2.0-1ubuntu1_amd64.deb ...\n",
      "Unpacking gfortran (4:11.2.0-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libnl-3-200:amd64.\n",
      "Preparing to unpack .../13-libnl-3-200_3.5.0-0.1_amd64.deb ...\n",
      "Unpacking libnl-3-200:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libnl-route-3-200:amd64.\n",
      "Preparing to unpack .../14-libnl-route-3-200_3.5.0-0.1_amd64.deb ...\n",
      "Unpacking libnl-route-3-200:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libibverbs1:amd64.\n",
      "Preparing to unpack .../15-libibverbs1_39.0-1_amd64.deb ...\n",
      "Unpacking libibverbs1:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package ibverbs-providers:amd64.\n",
      "Preparing to unpack .../16-ibverbs-providers_39.0-1_amd64.deb ...\n",
      "Unpacking ibverbs-providers:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package javascript-common.\n",
      "Preparing to unpack .../17-javascript-common_11+nmu1_all.deb ...\n",
      "Unpacking javascript-common (11+nmu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libevent-core-2.1-7:amd64.\n",
      "Preparing to unpack .../18-libevent-core-2.1-7_2.1.12-stable-1build3_amd64.deb ...\n",
      "Unpacking libevent-core-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libevent-pthreads-2.1-7:amd64.\n",
      "Preparing to unpack .../19-libevent-pthreads-2.1-7_2.1.12-stable-1build3_amd64.deb ...\n",
      "Unpacking libevent-pthreads-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libpsm-infinipath1.\n",
      "Preparing to unpack .../20-libpsm-infinipath1_3.3+20.604758e7-6.1_amd64.deb ...\n",
      "Unpacking libpsm-infinipath1 (3.3+20.604758e7-6.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package libpsm2-2.\n",
      "Preparing to unpack .../21-libpsm2-2_11.2.185-1_amd64.deb ...\n",
      "Unpacking libpsm2-2 (11.2.185-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package librdmacm1:amd64.\n",
      "Preparing to unpack .../22-librdmacm1_39.0-1_amd64.deb ...\n",
      "Unpacking librdmacm1:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libfabric1:amd64.\n",
      "Preparing to unpack .../23-libfabric1_1.11.0-3_amd64.deb ...\n",
      "Unpacking libfabric1:amd64 (1.11.0-3) ...\n",
      "Selecting previously unselected package libhwloc15:amd64.\n",
      "Preparing to unpack .../24-libhwloc15_2.7.0-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking libhwloc15:amd64 (2.7.0-2ubuntu1) ...\n",
      "Selecting previously unselected package libxnvctrl0:amd64.\n",
      "Preparing to unpack .../25-libxnvctrl0_575.57.08-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libxnvctrl0:amd64 (575.57.08-0ubuntu1) ...\n",
      "Selecting previously unselected package ocl-icd-libopencl1:amd64.\n",
      "Preparing to unpack .../26-ocl-icd-libopencl1_2.2.14-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking ocl-icd-libopencl1:amd64 (2.2.14-3) ...\n",
      "Selecting previously unselected package libhwloc-plugins:amd64.\n",
      "Preparing to unpack .../27-libhwloc-plugins_2.7.0-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking libhwloc-plugins:amd64 (2.7.0-2ubuntu1) ...\n",
      "Selecting previously unselected package libpmix2:amd64.\n",
      "Preparing to unpack .../28-libpmix2_4.1.2-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking libpmix2:amd64 (4.1.2-2ubuntu1) ...\n",
      "Selecting previously unselected package libucx0:amd64.\n",
      "Preparing to unpack .../29-libucx0_1.12.1~rc2-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking libucx0:amd64 (1.12.1~rc2-1) ...\n",
      "Selecting previously unselected package libopenmpi3:amd64.\n",
      "Preparing to unpack .../30-libopenmpi3_4.1.2-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking libopenmpi3:amd64 (4.1.2-2ubuntu1) ...\n",
      "Selecting previously unselected package libcaf-openmpi-3:amd64.\n",
      "Preparing to unpack .../31-libcaf-openmpi-3_2.9.2-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libcaf-openmpi-3:amd64 (2.9.2-3) ...\n",
      "Selecting previously unselected package libcoarrays-dev:amd64.\n",
      "Preparing to unpack .../32-libcoarrays-dev_2.9.2-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libcoarrays-dev:amd64 (2.9.2-3) ...\n",
      "Selecting previously unselected package openmpi-common.\n",
      "Preparing to unpack .../33-openmpi-common_4.1.2-2ubuntu1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking openmpi-common (4.1.2-2ubuntu1) ...\n",
      "Selecting previously unselected package openmpi-bin.\n",
      "Preparing to unpack .../34-openmpi-bin_4.1.2-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking openmpi-bin (4.1.2-2ubuntu1) ...\n",
      "Selecting previously unselected package libcoarrays-openmpi-dev:amd64.\n",
      "Preparing to unpack .../35-libcoarrays-openmpi-dev_2.9.2-3_amd64.deb ...\n",
      "Unpacking libcoarrays-openmpi-dev:amd64 (2.9.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libevent-2.1-7:amd64.\n",
      "Preparing to unpack .../36-libevent-2.1-7_2.1.12-stable-1build3_amd64.deb ...\n",
      "Unpacking libevent-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libevent-extra-2.1-7:amd64.\n",
      "Preparing to unpack .../37-libevent-extra-2.1-7_2.1.12-stable-1build3_amd64.deb ...\n",
      "Unpacking libevent-extra-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libevent-openssl-2.1-7:amd64.\n",
      "Preparing to unpack .../38-libevent-openssl-2.1-7_2.1.12-stable-1build3_amd64.deb ...\n",
      "Unpacking libevent-openssl-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libevent-dev.\n",
      "Preparing to unpack .../39-libevent-dev_2.1.12-stable-1build3_amd64.deb ...\n",
      "Unpacking libevent-dev (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package libjs-jquery.\n",
      "Preparing to unpack .../40-libjs-jquery_3.6.0+dfsg+~3.5.13-1_all.deb ...\n",
      "Unpacking libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package libjs-jquery-ui.\n",
      "Preparing to unpack .../41-libjs-jquery-ui_1.13.1+dfsg-1_all.deb ...\n",
      "Unpacking libjs-jquery-ui (1.13.1+dfsg-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libltdl7:amd64.\n",
      "Preparing to unpack .../42-libltdl7_2.4.6-15build2_amd64.deb ...\n",
      "Unpacking libltdl7:amd64 (2.4.6-15build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libltdl-dev:amd64.\n",
      "Preparing to unpack .../43-libltdl-dev_2.4.6-15build2_amd64.deb ...\n",
      "Unpacking libltdl-dev:amd64 (2.4.6-15build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package libnl-3-dev:amd64.\n",
      "Preparing to unpack .../44-libnl-3-dev_3.5.0-0.1_amd64.deb ...\n",
      "Unpacking libnl-3-dev:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [########################..................................] \u001b8Selecting previously unselected package libnl-route-3-dev:amd64.\n",
      "Preparing to unpack .../45-libnl-route-3-dev_3.5.0-0.1_amd64.deb ...\n",
      "Unpacking libnl-route-3-dev:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package libnuma-dev:amd64.\n",
      "Preparing to unpack .../46-libnuma-dev_2.0.14-3ubuntu2_amd64.deb ...\n",
      "Unpacking libnuma-dev:amd64 (2.0.14-3ubuntu2) ...\n",
      "Selecting previously unselected package libhwloc-dev:amd64.\n",
      "Preparing to unpack .../47-libhwloc-dev_2.7.0-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking libhwloc-dev:amd64 (2.7.0-2ubuntu1) ...\n",
      "Selecting previously unselected package libpmix-dev:amd64.\n",
      "Preparing to unpack .../48-libpmix-dev_4.1.2-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking libpmix-dev:amd64 (4.1.2-2ubuntu1) ...\n",
      "Selecting previously unselected package libtool.\n",
      "Preparing to unpack .../49-libtool_2.4.6-15build2_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking libtool (2.4.6-15build2) ...\n",
      "Selecting previously unselected package libibverbs-dev:amd64.\n",
      "Preparing to unpack .../50-libibverbs-dev_39.0-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking libibverbs-dev:amd64 (39.0-1) ...\n",
      "Selecting previously unselected package libopenmpi-dev:amd64.\n",
      "Preparing to unpack .../51-libopenmpi-dev_4.1.2-2ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking libopenmpi-dev:amd64 (4.1.2-2ubuntu1) ...\n",
      "Setting up javascript-common (11+nmu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libmagic-mgc (1:5.41-3ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libmagic1:amd64 (1:5.41-3ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up file (1:5.41-3ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libxnvctrl0:amd64 (575.57.08-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up autotools-dev (20220109.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libsigsegv2:amd64 (2.13-1ubuntu3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libhwloc15:amd64 (2.7.0-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libevent-core-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libevent-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libltdl7:amd64 (2.4.6-15build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libgfortran5:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libnuma1:amd64 (2.0.14-3ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up ocl-icd-libopencl1:amd64 (2.2.14-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up libnl-3-200:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libpsm2-2 (11.2.185-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up openmpi-common (4.1.2-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libpsm-infinipath1 (3.3+20.604758e7-6.1) ...\n",
      "update-alternatives: using /usr/lib/libpsm1/libpsm_infinipath.so.1.16 to provide /usr/lib/x86_64-linux-gnu/libpsm_infinipath.so.1 (libpsm_infinipath.so.1) in auto mode\n",
      "Setting up libjs-jquery (3.6.0+dfsg+~3.5.13-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libevent-pthreads-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libevent-extra-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libtool (2.4.6-15build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libgfortran-11-dev:amd64 (11.4.0-1ubuntu1~22.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libevent-openssl-2.1-7:amd64 (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up m4 (1.4.18-5ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up libhwloc-plugins:amd64 (2.7.0-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libnuma-dev:amd64 (2.0.14-3ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libnl-route-3-200:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libjs-jquery-ui (1.13.1+dfsg-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up libevent-dev (2.1.12-stable-1build3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up gfortran-11 (11.4.0-1ubuntu1~22.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up autoconf (2.71-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up libnl-3-dev:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up automake (1:1.16.5-1.3) ...\n",
      "update-alternatives: using /usr/bin/automake-1.16 to provide /usr/bin/automake (automake) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/automake.1.gz because associated file /usr/share/man/man1/automake-1.16.1.gz (of link group automake) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/aclocal.1.gz because associated file /usr/share/man/man1/aclocal-1.16.1.gz (of link group automake) doesn't exist\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libibverbs1:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up libpmix2:amd64 (4.1.2-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up ibverbs-providers:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up gfortran (4:11.2.0-1ubuntu1) ...\n",
      "update-alternatives: using /usr/bin/gfortran to provide /usr/bin/f95 (f95) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/f95.1.gz because associated file /usr/share/man/man1/gfortran.1.gz (of link group f95) doesn't exist\n",
      "update-alternatives: using /usr/bin/gfortran to provide /usr/bin/f77 (f77) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/f77.1.gz because associated file /usr/share/man/man1/gfortran.1.gz (of link group f77) doesn't exist\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up libnl-route-3-dev:amd64 (3.5.0-0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up libltdl-dev:amd64 (2.4.6-15build2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up libhwloc-dev:amd64 (2.7.0-2ubuntu1) ...\n",
      "Setting up libpmix-dev:amd64 (4.1.2-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up librdmacm1:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libucx0:amd64 (1.12.1~rc2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up libcoarrays-dev:amd64 (2.9.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up libibverbs-dev:amd64 (39.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libfabric1:amd64 (1.11.0-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libopenmpi3:amd64 (4.1.2-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up libcaf-openmpi-3:amd64 (2.9.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up openmpi-bin (4.1.2-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8update-alternatives: using /usr/bin/mpirun.openmpi to provide /usr/bin/mpirun (mpirun) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpirun.1.gz because associated file /usr/share/man/man1/mpirun.openmpi.1.gz (of link group mpirun) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpiexec.1.gz because associated file /usr/share/man/man1/mpiexec.openmpi.1.gz (of link group mpirun) doesn't exist\n",
      "update-alternatives: using /usr/bin/mpicc.openmpi to provide /usr/bin/mpicc (mpi) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpicc.1.gz because associated file /usr/share/man/man1/mpicc.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpic++.1.gz because associated file /usr/share/man/man1/mpic++.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpicxx.1.gz because associated file /usr/share/man/man1/mpicxx.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpiCC.1.gz because associated file /usr/share/man/man1/mpiCC.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpif77.1.gz because associated file /usr/share/man/man1/mpif77.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpif90.1.gz because associated file /usr/share/man/man1/mpif90.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/mpifort.1.gz because associated file /usr/share/man/man1/mpifort.openmpi.1.gz (of link group mpi) doesn't exist\n",
      "Setting up libcoarrays-openmpi-dev:amd64 (2.9.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8update-alternatives: using /usr/lib/x86_64-linux-gnu/open-coarrays/openmpi/bin/caf to provide /usr/bin/caf.openmpi (caf-openmpi) in auto mode\n",
      "update-alternatives: using /usr/bin/caf.openmpi to provide /usr/bin/caf (caf) in auto mode\n",
      "Setting up libopenmpi-dev:amd64 (4.1.2-2ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8update-alternatives: using /usr/lib/x86_64-linux-gnu/openmpi/include to provide /usr/include/x86_64-linux-gnu/mpi (mpi-x86_64-linux-gnu) in auto mode\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install -y build-essential openmpi-bin libopenmpi-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjVC3ZR6oQ0q",
    "outputId": "cab24475-d4b8-498c-d86e-1cc0a78c6a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mpi4py\n",
      "  Using cached mpi4py-4.0.3.tar.gz (466 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: mpi4py\n",
      "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp310-cp310-linux_x86_64.whl size=4255575 sha256=8277585b4f33aac2445dc7b871d918e7ee57bb1dcb83e533fcf77a8b295b6bf3\n",
      "  Stored in directory: /root/.cache/pip/wheels/94/57/cc/2e34c76a8690ce2a90b200702473f579b23f8224b5058b6a6d\n",
      "Successfully built mpi4py\n",
      "Installing collected packages: mpi4py\n",
      "Successfully installed mpi4py-4.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ExrQ9a7uoHZW",
    "outputId": "03ec0a8d-f851-4c96-c968-6a3b14d51d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Time-LLM\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/Time-LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB2Pic2Tr-um",
    "outputId": "128d90c5-9c03-4b16-852b-052c95fd3c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 5, in <module>\n",
      "    from accelerate.commands.accelerate_cli import main\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 19, in <module>\n",
      "    from accelerate.commands.estimate import estimate_command_parser\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/estimate.py\", line 34, in <module>\n",
      "    import timm\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/__init__.py\", line 2, in <module>\n",
      "    from .layers import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/__init__.py\", line 8, in <module>\n",
      "    from .classifier import create_classifier, ClassifierHead, NormMlpClassifierHead, ClNormMlpClassifierHead\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/classifier.py\", line 15, in <module>\n",
      "    from .create_norm import get_norm_layer\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/create_norm.py\", line 14, in <module>\n",
      "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\", line 163, in <module>\n",
      "    @torch.library.register_fake(\"torchvision::nms\")\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.library' has no attribute 'register_fake'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 5, in <module>\n",
      "    from accelerate.commands.accelerate_cli import main\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 19, in <module>\n",
      "    from accelerate.commands.estimate import estimate_command_parser\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/estimate.py\", line 34, in <module>\n",
      "    import timm\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/__init__.py\", line 2, in <module>\n",
      "    from .layers import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/__init__.py\", line 8, in <module>\n",
      "    from .classifier import create_classifier, ClassifierHead, NormMlpClassifierHead, ClNormMlpClassifierHead\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/classifier.py\", line 15, in <module>\n",
      "    from .create_norm import get_norm_layer\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/create_norm.py\", line 14, in <module>\n",
      "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\", line 163, in <module>\n",
      "    @torch.library.register_fake(\"torchvision::nms\")\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.library' has no attribute 'register_fake'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 5, in <module>\n",
      "    from accelerate.commands.accelerate_cli import main\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 19, in <module>\n",
      "    from accelerate.commands.estimate import estimate_command_parser\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/estimate.py\", line 34, in <module>\n",
      "    import timm\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/__init__.py\", line 2, in <module>\n",
      "    from .layers import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/__init__.py\", line 8, in <module>\n",
      "    from .classifier import create_classifier, ClassifierHead, NormMlpClassifierHead, ClNormMlpClassifierHead\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/classifier.py\", line 15, in <module>\n",
      "    from .create_norm import get_norm_layer\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/create_norm.py\", line 14, in <module>\n",
      "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\", line 163, in <module>\n",
      "    @torch.library.register_fake(\"torchvision::nms\")\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.library' has no attribute 'register_fake'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/accelerate\", line 5, in <module>\n",
      "    from accelerate.commands.accelerate_cli import main\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 19, in <module>\n",
      "    from accelerate.commands.estimate import estimate_command_parser\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/estimate.py\", line 34, in <module>\n",
      "    import timm\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/__init__.py\", line 2, in <module>\n",
      "    from .layers import (\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/__init__.py\", line 8, in <module>\n",
      "    from .classifier import create_classifier, ClassifierHead, NormMlpClassifierHead, ClNormMlpClassifierHead\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/classifier.py\", line 15, in <module>\n",
      "    from .create_norm import get_norm_layer\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/create_norm.py\", line 14, in <module>\n",
      "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\", line 163, in <module>\n",
      "    @torch.library.register_fake(\"torchvision::nms\")\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'torch.library' has no attribute 'register_fake'\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/TimeLLM_ETTh1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-OKptz2gplS",
    "outputId": "8a15de8a-a4a5-4ad9-9f80-a4eaeaaa0452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victor-250612-Choosing 2B/7B\n",
      "\n",
      "--- Starting Gemma 2B Loading Process ---\n",
      "Loading tokenizer for 'google/gemma-2b'...\n",
      "Tokenizer loaded successfully.\n",
      "Loading model 'google/gemma-2b'... This may take a few minutes and download several gigabytes.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.20it/s]\n",
      "Model loaded successfully and moved to the appropriate device.\n",
      "[2025-06-12 10:28:11,211] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-06-12 10:28:11,342] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2025-06-12 10:28:11,342] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2025-06-12 10:28:11,343] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-06-12 10:28:12,161] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.19.0.2, master_port=29500\n",
      "[2025-06-12 10:28:12,161] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-06-12 10:28:13,645] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-06-12 10:28:13,646] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2025-06-12 10:28:13,646] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-06-12 10:28:13,647] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2025-06-12 10:28:13,647] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2025-06-12 10:28:13,647] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2025-06-12 10:28:13,647] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2025-06-12 10:28:13,647] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2025-06-12 10:28:13,647] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2025-06-12 10:28:13,647] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2025-06-12 10:28:15,479] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2025-06-12 10:28:15,481] [INFO] [utils.py:801:see_memory_usage] MA 6.17 GB         Max_MA 6.65 GB         CA 6.66 GB         Max_CA 7 GB \n",
      "[2025-06-12 10:28:15,481] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 50.62 GB, percent = 3.3%\n",
      "[2025-06-12 10:28:15,633] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2025-06-12 10:28:15,633] [INFO] [utils.py:801:see_memory_usage] MA 6.17 GB         Max_MA 7.13 GB         CA 7.62 GB         Max_CA 8 GB \n",
      "[2025-06-12 10:28:15,634] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 50.62 GB, percent = 3.3%\n",
      "[2025-06-12 10:28:15,634] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2025-06-12 10:28:15,803] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-06-12 10:28:15,804] [INFO] [utils.py:801:see_memory_usage] MA 6.17 GB         Max_MA 6.17 GB         CA 7.62 GB         Max_CA 8 GB \n",
      "[2025-06-12 10:28:15,804] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 50.62 GB, percent = 3.3%\n",
      "[2025-06-12 10:28:15,805] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2025-06-12 10:28:15,806] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2025-06-12 10:28:15,806] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-06-12 10:28:15,806] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[4.000000000000002e-06], mom=[(0.95, 0.999)]\n",
      "[2025-06-12 10:28:15,807] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2025-06-12 10:28:15,807] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-06-12 10:28:15,807] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2025-06-12 10:28:15,807] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2025-06-12 10:28:15,807] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x70ff37e25330>\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2025-06-12 10:28:15,808] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-06-12 10:28:15,809] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2025-06-12 10:28:15,810] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2025-06-12 10:28:15,811] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "99it [00:24,  4.41it/s]\titers: 100, epoch: 1 | loss: 0.4484976\n",
      "\tspeed: 0.2914s/iter; left time: 5356.9491s\n",
      "199it [00:46,  4.45it/s]\titers: 200, epoch: 1 | loss: 0.5634706\n",
      "\tspeed: 0.2257s/iter; left time: 4126.4714s\n",
      "299it [01:09,  4.39it/s]\titers: 300, epoch: 1 | loss: 0.4317776\n",
      "\tspeed: 0.2283s/iter; left time: 4150.5603s\n",
      "399it [01:32,  4.50it/s]\titers: 400, epoch: 1 | loss: 0.4833643\n",
      "\tspeed: 0.2315s/iter; left time: 4186.3311s\n",
      "499it [01:56,  4.38it/s]\titers: 500, epoch: 1 | loss: 0.4413104\n",
      "\tspeed: 0.2347s/iter; left time: 4220.5993s\n",
      "599it [02:20,  4.04it/s]\titers: 600, epoch: 1 | loss: 0.3587468\n",
      "\tspeed: 0.2396s/iter; left time: 4284.6140s\n",
      "699it [02:43,  4.08it/s]\titers: 700, epoch: 1 | loss: 0.3478580\n",
      "\tspeed: 0.2306s/iter; left time: 4100.3915s\n",
      "799it [03:06,  4.39it/s]\titers: 800, epoch: 1 | loss: 0.7186305\n",
      "\tspeed: 0.2326s/iter; left time: 4112.4272s\n",
      "899it [03:29,  4.02it/s]\titers: 900, epoch: 1 | loss: 0.3679289\n",
      "\tspeed: 0.2282s/iter; left time: 4011.7583s\n",
      "999it [03:52,  4.40it/s]\titers: 1000, epoch: 1 | loss: 0.5036504\n",
      "\tspeed: 0.2266s/iter; left time: 3960.6729s\n",
      "1099it [04:15,  4.27it/s]\titers: 1100, epoch: 1 | loss: 0.3857997\n",
      "\tspeed: 0.2375s/iter; left time: 4128.3557s\n",
      "1199it [04:38,  3.85it/s]\titers: 1200, epoch: 1 | loss: 0.5690258\n",
      "\tspeed: 0.2301s/iter; left time: 3975.6083s\n",
      "1299it [05:01,  4.73it/s]\titers: 1300, epoch: 1 | loss: 0.3191913\n",
      "\tspeed: 0.2243s/iter; left time: 3853.8617s\n",
      "1399it [05:23,  4.49it/s]\titers: 1400, epoch: 1 | loss: 0.3482029\n",
      "\tspeed: 0.2215s/iter; left time: 3783.8541s\n",
      "1499it [05:46,  4.50it/s]\titers: 1500, epoch: 1 | loss: 0.4966134\n",
      "\tspeed: 0.2313s/iter; left time: 3927.4881s\n",
      "1599it [06:10,  4.43it/s]\titers: 1600, epoch: 1 | loss: 0.3906970\n",
      "\tspeed: 0.2357s/iter; left time: 3979.4887s\n",
      "1699it [06:33,  4.48it/s]\titers: 1700, epoch: 1 | loss: 0.3015500\n",
      "\tspeed: 0.2334s/iter; left time: 3916.7998s\n",
      "1799it [06:56,  4.59it/s]\titers: 1800, epoch: 1 | loss: 0.5289065\n",
      "\tspeed: 0.2285s/iter; left time: 3810.8876s\n",
      "1848it [07:07,  4.32it/s]\n",
      "Epoch: 1 cost time: 427.3159840106964\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:10,  8.69it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:13,  8.25it/s]\n",
      "Epoch: 1 | Train Loss: 0.4943013 Vali Loss: 0.8432579 Test Loss: 0.4809900 MAE Loss: 0.4601448\n",
      "lr = 0.0000040000\n",
      "Updating learning rate to 4.000000000000002e-06\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:24,  4.58it/s]\titers: 100, epoch: 2 | loss: 0.3623345\n",
      "\tspeed: 1.8625s/iter; left time: 30792.9921s\n",
      "199it [00:48,  4.40it/s]\titers: 200, epoch: 2 | loss: 0.4504485\n",
      "\tspeed: 0.2359s/iter; left time: 3876.4392s\n",
      "299it [01:11,  4.29it/s]\titers: 300, epoch: 2 | loss: 0.4085125\n",
      "\tspeed: 0.2326s/iter; left time: 3798.3972s\n",
      "399it [01:34,  4.23it/s]\titers: 400, epoch: 2 | loss: 0.4239410\n",
      "\tspeed: 0.2325s/iter; left time: 3774.8470s\n",
      "499it [01:57,  4.64it/s]\titers: 500, epoch: 2 | loss: 0.3954042\n",
      "\tspeed: 0.2333s/iter; left time: 3763.4529s\n",
      "599it [02:21,  4.72it/s]\titers: 600, epoch: 2 | loss: 0.4574141\n",
      "\tspeed: 0.2348s/iter; left time: 3764.6154s\n",
      "699it [02:43,  4.43it/s]\titers: 700, epoch: 2 | loss: 0.4775932\n",
      "\tspeed: 0.2243s/iter; left time: 3573.4200s\n",
      "799it [03:06,  4.44it/s]\titers: 800, epoch: 2 | loss: 0.4984720\n",
      "\tspeed: 0.2286s/iter; left time: 3620.1487s\n",
      "899it [03:29,  4.48it/s]\titers: 900, epoch: 2 | loss: 0.4619668\n",
      "\tspeed: 0.2308s/iter; left time: 3630.7627s\n",
      "999it [03:53,  3.99it/s]\titers: 1000, epoch: 2 | loss: 0.2836932\n",
      "\tspeed: 0.2407s/iter; left time: 3762.6221s\n",
      "1099it [04:17,  4.31it/s]\titers: 1100, epoch: 2 | loss: 0.3942816\n",
      "\tspeed: 0.2363s/iter; left time: 3669.8158s\n",
      "1199it [04:41,  4.34it/s]\titers: 1200, epoch: 2 | loss: 0.3482413\n",
      "\tspeed: 0.2382s/iter; left time: 3676.8747s\n",
      "1299it [05:04,  4.33it/s]\titers: 1300, epoch: 2 | loss: 0.3076162\n",
      "\tspeed: 0.2333s/iter; left time: 3577.1708s\n",
      "1399it [05:28,  3.98it/s]\titers: 1400, epoch: 2 | loss: 0.8036815\n",
      "\tspeed: 0.2441s/iter; left time: 3719.0050s\n",
      "1499it [05:52,  4.37it/s]\titers: 1500, epoch: 2 | loss: 0.4081330\n",
      "\tspeed: 0.2396s/iter; left time: 3625.2478s\n",
      "1599it [06:16,  4.38it/s]\titers: 1600, epoch: 2 | loss: 0.3617728\n",
      "\tspeed: 0.2321s/iter; left time: 3489.2129s\n",
      "1699it [06:38,  4.66it/s]\titers: 1700, epoch: 2 | loss: 0.4178190\n",
      "\tspeed: 0.2243s/iter; left time: 3348.8081s\n",
      "1799it [07:00,  4.71it/s]\titers: 1800, epoch: 2 | loss: 0.3427238\n",
      "\tspeed: 0.2197s/iter; left time: 3258.8666s\n",
      "1848it [07:11,  4.28it/s]\n",
      "Epoch: 2 cost time: 431.5919017791748\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:08,  8.84it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:24,  7.19it/s]\n",
      "Epoch: 2 | Train Loss: 0.4262435 Vali Loss: 0.7777321 Test Loss: 0.4368140 MAE Loss: 0.4362730\n",
      "Updating learning rate to 2.000000000000001e-06\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:29,  4.20it/s]\titers: 100, epoch: 3 | loss: 0.4084603\n",
      "\tspeed: 2.0252s/iter; left time: 29740.5639s\n",
      "199it [00:52,  4.41it/s]\titers: 200, epoch: 3 | loss: 0.3356048\n",
      "\tspeed: 0.2274s/iter; left time: 3316.0138s\n",
      "299it [01:14,  4.43it/s]\titers: 300, epoch: 3 | loss: 0.3579765\n",
      "\tspeed: 0.2277s/iter; left time: 3298.1203s\n",
      "399it [01:38,  4.27it/s]\titers: 400, epoch: 3 | loss: 0.3286968\n",
      "\tspeed: 0.2381s/iter; left time: 3424.8925s\n",
      "499it [02:02,  4.09it/s]\titers: 500, epoch: 3 | loss: 0.5582854\n",
      "\tspeed: 0.2423s/iter; left time: 3461.6422s\n",
      "599it [02:27,  4.17it/s]\titers: 600, epoch: 3 | loss: 0.4965847\n",
      "\tspeed: 0.2448s/iter; left time: 3472.9858s\n",
      "699it [02:50,  4.65it/s]\titers: 700, epoch: 3 | loss: 0.5190301\n",
      "\tspeed: 0.2352s/iter; left time: 3312.1148s\n",
      "799it [03:13,  4.37it/s]\titers: 800, epoch: 3 | loss: 0.4560746\n",
      "\tspeed: 0.2223s/iter; left time: 3108.1943s\n",
      "899it [03:36,  4.58it/s]\titers: 900, epoch: 3 | loss: 0.2941086\n",
      "\tspeed: 0.2357s/iter; left time: 3272.7361s\n",
      "999it [03:58,  4.39it/s]\titers: 1000, epoch: 3 | loss: 0.4007950\n",
      "\tspeed: 0.2207s/iter; left time: 3042.3403s\n",
      "1099it [04:21,  4.48it/s]\titers: 1100, epoch: 3 | loss: 0.3747275\n",
      "\tspeed: 0.2266s/iter; left time: 3101.2848s\n",
      "1199it [04:44,  4.41it/s]\titers: 1200, epoch: 3 | loss: 0.3960532\n",
      "\tspeed: 0.2328s/iter; left time: 3162.6285s\n",
      "1299it [05:07,  4.45it/s]\titers: 1300, epoch: 3 | loss: 0.6398332\n",
      "\tspeed: 0.2255s/iter; left time: 3040.7801s\n",
      "1399it [05:30,  4.38it/s]\titers: 1400, epoch: 3 | loss: 0.2769712\n",
      "\tspeed: 0.2330s/iter; left time: 3118.4430s\n",
      "1499it [05:53,  3.97it/s]\titers: 1500, epoch: 3 | loss: 0.3409202\n",
      "\tspeed: 0.2337s/iter; left time: 3104.2698s\n",
      "1599it [06:17,  4.45it/s]\titers: 1600, epoch: 3 | loss: 0.2733633\n",
      "\tspeed: 0.2350s/iter; left time: 3098.5596s\n",
      "1699it [06:40,  3.93it/s]\titers: 1700, epoch: 3 | loss: 0.4103539\n",
      "\tspeed: 0.2335s/iter; left time: 3054.8701s\n",
      "1799it [07:03,  4.32it/s]\titers: 1800, epoch: 3 | loss: 0.4777911\n",
      "\tspeed: 0.2303s/iter; left time: 2991.0523s\n",
      "1848it [07:16,  4.24it/s]\n",
      "Epoch: 3 cost time: 436.14221239089966\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:14,  8.19it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:13,  8.30it/s]\n",
      "Epoch: 3 | Train Loss: 0.4113598 Vali Loss: 0.7600505 Test Loss: 0.4233074 MAE Loss: 0.4273293\n",
      "Updating learning rate to 1.0000000000000006e-06\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:24,  4.44it/s]\titers: 100, epoch: 4 | loss: 0.3423021\n",
      "\tspeed: 1.9131s/iter; left time: 24558.2791s\n",
      "199it [00:48,  4.44it/s]\titers: 200, epoch: 4 | loss: 0.3762256\n",
      "\tspeed: 0.2384s/iter; left time: 3036.8858s\n",
      "299it [01:11,  4.29it/s]\titers: 300, epoch: 4 | loss: 0.5004815\n",
      "\tspeed: 0.2328s/iter; left time: 2941.8842s\n",
      "399it [01:34,  4.30it/s]\titers: 400, epoch: 4 | loss: 0.5289816\n",
      "\tspeed: 0.2310s/iter; left time: 2896.5763s\n",
      "499it [01:58,  4.44it/s]\titers: 500, epoch: 4 | loss: 0.4071257\n",
      "\tspeed: 0.2386s/iter; left time: 2966.9424s\n",
      "599it [02:21,  3.50it/s]\titers: 600, epoch: 4 | loss: 0.3685633\n",
      "\tspeed: 0.2367s/iter; left time: 2920.5845s\n",
      "699it [02:44,  4.45it/s]\titers: 700, epoch: 4 | loss: 0.3335404\n",
      "\tspeed: 0.2227s/iter; left time: 2725.4385s\n",
      "799it [03:06,  4.34it/s]\titers: 800, epoch: 4 | loss: 0.5481560\n",
      "\tspeed: 0.2269s/iter; left time: 2753.4765s\n",
      "899it [03:29,  4.75it/s]\titers: 900, epoch: 4 | loss: 0.5540723\n",
      "\tspeed: 0.2218s/iter; left time: 2670.3182s\n",
      "999it [03:52,  4.49it/s]\titers: 1000, epoch: 4 | loss: 0.5443359\n",
      "\tspeed: 0.2346s/iter; left time: 2800.4939s\n",
      "1099it [04:15,  4.37it/s]\titers: 1100, epoch: 4 | loss: 0.4034224\n",
      "\tspeed: 0.2315s/iter; left time: 2740.5958s\n",
      "1199it [04:39,  4.44it/s]\titers: 1200, epoch: 4 | loss: 0.3618282\n",
      "\tspeed: 0.2406s/iter; left time: 2823.9955s\n",
      "1299it [05:03,  4.45it/s]\titers: 1300, epoch: 4 | loss: 0.7028723\n",
      "\tspeed: 0.2360s/iter; left time: 2745.8496s\n",
      "1399it [05:27,  4.39it/s]\titers: 1400, epoch: 4 | loss: 0.3186139\n",
      "\tspeed: 0.2383s/iter; left time: 2749.6030s\n",
      "1499it [05:50,  4.17it/s]\titers: 1500, epoch: 4 | loss: 0.3620951\n",
      "\tspeed: 0.2353s/iter; left time: 2691.0986s\n",
      "1599it [06:14,  4.35it/s]\titers: 1600, epoch: 4 | loss: 0.2606556\n",
      "\tspeed: 0.2380s/iter; left time: 2698.6335s\n",
      "1699it [06:38,  4.11it/s]\titers: 1700, epoch: 4 | loss: 0.3474462\n",
      "\tspeed: 0.2365s/iter; left time: 2657.2382s\n",
      "1799it [07:01,  4.37it/s]\titers: 1800, epoch: 4 | loss: 0.5174609\n",
      "\tspeed: 0.2303s/iter; left time: 2564.5141s\n",
      "1848it [07:12,  4.27it/s]\n",
      "Epoch: 4 cost time: 432.80946683883667\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:11,  8.54it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:15,  8.04it/s]\n",
      "Epoch: 4 | Train Loss: 0.4061191 Vali Loss: 0.7570550 Test Loss: 0.4207059 MAE Loss: 0.4260992\n",
      "Updating learning rate to 5.000000000000003e-07\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:24,  4.56it/s]\titers: 100, epoch: 5 | loss: 0.3552710\n",
      "\tspeed: 1.9108s/iter; left time: 20997.9267s\n",
      "199it [00:48,  4.33it/s]\titers: 200, epoch: 5 | loss: 0.3126781\n",
      "\tspeed: 0.2410s/iter; left time: 2624.5225s\n",
      "299it [01:12,  4.40it/s]\titers: 300, epoch: 5 | loss: 0.6498153\n",
      "\tspeed: 0.2347s/iter; left time: 2532.4964s\n",
      "399it [01:35,  4.37it/s]\titers: 400, epoch: 5 | loss: 0.3889223\n",
      "\tspeed: 0.2345s/iter; left time: 2506.5780s\n",
      "499it [01:59,  3.74it/s]\titers: 500, epoch: 5 | loss: 0.3080748\n",
      "\tspeed: 0.2399s/iter; left time: 2540.0883s\n",
      "599it [02:22,  4.39it/s]\titers: 600, epoch: 5 | loss: 0.2527446\n",
      "\tspeed: 0.2357s/iter; left time: 2472.3569s\n",
      "699it [02:46,  4.37it/s]\titers: 700, epoch: 5 | loss: 0.5134723\n",
      "\tspeed: 0.2356s/iter; left time: 2447.6104s\n",
      "799it [03:11,  3.42it/s]\titers: 800, epoch: 5 | loss: 0.4651283\n",
      "\tspeed: 0.2529s/iter; left time: 2602.0517s\n",
      "899it [03:39,  3.53it/s]\titers: 900, epoch: 5 | loss: 0.3794961\n",
      "\tspeed: 0.2760s/iter; left time: 2812.5430s\n",
      "999it [04:05,  3.91it/s]\titers: 1000, epoch: 5 | loss: 0.5154995\n",
      "\tspeed: 0.2610s/iter; left time: 2633.4627s\n",
      "1099it [04:32,  3.67it/s]\titers: 1100, epoch: 5 | loss: 0.6166574\n",
      "\tspeed: 0.2671s/iter; left time: 2668.1794s\n",
      "1199it [04:59,  3.31it/s]\titers: 1200, epoch: 5 | loss: 0.3840702\n",
      "\tspeed: 0.2759s/iter; left time: 2728.1545s\n",
      "1299it [05:25,  4.41it/s]\titers: 1300, epoch: 5 | loss: 0.4935557\n",
      "\tspeed: 0.2607s/iter; left time: 2551.9221s\n",
      "1399it [05:51,  4.14it/s]\titers: 1400, epoch: 5 | loss: 0.3814735\n",
      "\tspeed: 0.2512s/iter; left time: 2433.8373s\n",
      "1499it [06:15,  4.00it/s]\titers: 1500, epoch: 5 | loss: 0.3343373\n",
      "\tspeed: 0.2410s/iter; left time: 2311.3420s\n",
      "1599it [06:39,  3.68it/s]\titers: 1600, epoch: 5 | loss: 0.5487567\n",
      "\tspeed: 0.2434s/iter; left time: 2309.1818s\n",
      "1699it [07:03,  4.19it/s]\titers: 1700, epoch: 5 | loss: 0.4033285\n",
      "\tspeed: 0.2422s/iter; left time: 2273.8464s\n",
      "1799it [07:28,  4.09it/s]\titers: 1800, epoch: 5 | loss: 0.3798706\n",
      "\tspeed: 0.2437s/iter; left time: 2263.7996s\n",
      "1848it [07:40,  4.01it/s]\n",
      "Epoch: 5 cost time: 460.47074127197266\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:17,  7.88it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:29,  6.79it/s]\n",
      "Epoch: 5 | Train Loss: 0.4033805 Vali Loss: 0.7497947 Test Loss: 0.4167309 MAE Loss: 0.4235720\n",
      "Updating learning rate to 2.5000000000000015e-07\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:26,  3.99it/s]\titers: 100, epoch: 6 | loss: 0.3799662\n",
      "\tspeed: 2.1554s/iter; left time: 19702.6718s\n",
      "199it [00:54,  3.71it/s]\titers: 200, epoch: 6 | loss: 0.4579613\n",
      "\tspeed: 0.2775s/iter; left time: 2509.2442s\n",
      "299it [01:21,  3.82it/s]\titers: 300, epoch: 6 | loss: 0.3783818\n",
      "\tspeed: 0.2757s/iter; left time: 2465.0341s\n",
      "399it [01:48,  3.77it/s]\titers: 400, epoch: 6 | loss: 0.4598581\n",
      "\tspeed: 0.2711s/iter; left time: 2396.8027s\n",
      "499it [02:14,  4.22it/s]\titers: 500, epoch: 6 | loss: 0.4353451\n",
      "\tspeed: 0.2579s/iter; left time: 2254.6881s\n",
      "599it [02:40,  4.47it/s]\titers: 600, epoch: 6 | loss: 0.3193961\n",
      "\tspeed: 0.2572s/iter; left time: 2222.8717s\n",
      "699it [03:03,  4.31it/s]\titers: 700, epoch: 6 | loss: 0.4187107\n",
      "\tspeed: 0.2317s/iter; left time: 1979.1534s\n",
      "799it [03:26,  4.64it/s]\titers: 800, epoch: 6 | loss: 0.3741174\n",
      "\tspeed: 0.2268s/iter; left time: 1914.7561s\n",
      "899it [03:48,  4.55it/s]\titers: 900, epoch: 6 | loss: 0.3449280\n",
      "\tspeed: 0.2247s/iter; left time: 1874.0127s\n",
      "999it [04:13,  3.81it/s]\titers: 1000, epoch: 6 | loss: 0.4077867\n",
      "\tspeed: 0.2521s/iter; left time: 2077.2446s\n",
      "1099it [04:40,  4.21it/s]\titers: 1100, epoch: 6 | loss: 0.2921137\n",
      "\tspeed: 0.2637s/iter; left time: 2146.8355s\n",
      "1199it [05:04,  3.64it/s]\titers: 1200, epoch: 6 | loss: 0.2709661\n",
      "\tspeed: 0.2419s/iter; left time: 1945.3700s\n",
      "1299it [05:27,  4.61it/s]\titers: 1300, epoch: 6 | loss: 0.2544343\n",
      "\tspeed: 0.2307s/iter; left time: 1831.9800s\n",
      "1399it [05:50,  4.41it/s]\titers: 1400, epoch: 6 | loss: 0.5111430\n",
      "\tspeed: 0.2337s/iter; left time: 1832.3846s\n",
      "1499it [06:12,  4.67it/s]\titers: 1500, epoch: 6 | loss: 0.4914997\n",
      "\tspeed: 0.2191s/iter; left time: 1696.0777s\n",
      "1599it [06:35,  4.07it/s]\titers: 1600, epoch: 6 | loss: 0.3424436\n",
      "\tspeed: 0.2266s/iter; left time: 1731.5820s\n",
      "1699it [06:57,  4.67it/s]\titers: 1700, epoch: 6 | loss: 0.4163365\n",
      "\tspeed: 0.2263s/iter; left time: 1706.4234s\n",
      "1799it [07:20,  4.61it/s]\titers: 1800, epoch: 6 | loss: 0.4239498\n",
      "\tspeed: 0.2274s/iter; left time: 1691.8220s\n",
      "1848it [07:31,  4.09it/s]\n",
      "Epoch: 6 cost time: 451.8691620826721\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:08,  8.86it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:12,  8.43it/s]\n",
      "Epoch: 6 | Train Loss: 0.4020347 Vali Loss: 0.7468132 Test Loss: 0.4163140 MAE Loss: 0.4232968\n",
      "Updating learning rate to 1.2500000000000007e-07\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:22,  4.30it/s]\titers: 100, epoch: 7 | loss: 0.3677762\n",
      "\tspeed: 1.8286s/iter; left time: 13336.2897s\n",
      "199it [00:45,  4.33it/s]\titers: 200, epoch: 7 | loss: 0.3221188\n",
      "\tspeed: 0.2294s/iter; left time: 1650.1285s\n",
      "299it [01:08,  4.63it/s]\titers: 300, epoch: 7 | loss: 0.8219433\n",
      "\tspeed: 0.2253s/iter; left time: 1598.3612s\n",
      "399it [01:31,  4.63it/s]\titers: 400, epoch: 7 | loss: 0.4760606\n",
      "\tspeed: 0.2287s/iter; left time: 1599.4534s\n",
      "499it [01:53,  4.71it/s]\titers: 500, epoch: 7 | loss: 0.4094175\n",
      "\tspeed: 0.2221s/iter; left time: 1531.0626s\n",
      "599it [02:16,  4.62it/s]\titers: 600, epoch: 7 | loss: 0.4156286\n",
      "\tspeed: 0.2263s/iter; left time: 1537.2288s\n",
      "699it [02:39,  3.88it/s]\titers: 700, epoch: 7 | loss: 0.5277565\n",
      "\tspeed: 0.2357s/iter; left time: 1577.3160s\n",
      "799it [03:02,  4.62it/s]\titers: 800, epoch: 7 | loss: 0.3874102\n",
      "\tspeed: 0.2259s/iter; left time: 1489.0502s\n",
      "899it [03:25,  4.42it/s]\titers: 900, epoch: 7 | loss: 0.3199866\n",
      "\tspeed: 0.2347s/iter; left time: 1524.0971s\n",
      "999it [03:47,  4.69it/s]\titers: 1000, epoch: 7 | loss: 0.2732512\n",
      "\tspeed: 0.2194s/iter; left time: 1402.4191s\n",
      "1099it [04:10,  4.35it/s]\titers: 1100, epoch: 7 | loss: 0.3626000\n",
      "\tspeed: 0.2276s/iter; left time: 1432.4040s\n",
      "1199it [04:33,  4.69it/s]\titers: 1200, epoch: 7 | loss: 0.6278386\n",
      "\tspeed: 0.2292s/iter; left time: 1419.4536s\n",
      "1299it [04:55,  4.58it/s]\titers: 1300, epoch: 7 | loss: 0.5129881\n",
      "\tspeed: 0.2233s/iter; left time: 1360.6858s\n",
      "1399it [05:18,  4.50it/s]\titers: 1400, epoch: 7 | loss: 0.2017903\n",
      "\tspeed: 0.2244s/iter; left time: 1344.5993s\n",
      "1499it [05:40,  4.65it/s]\titers: 1500, epoch: 7 | loss: 0.3967377\n",
      "\tspeed: 0.2245s/iter; left time: 1322.8765s\n",
      "1599it [06:02,  4.61it/s]\titers: 1600, epoch: 7 | loss: 0.4442387\n",
      "\tspeed: 0.2229s/iter; left time: 1291.1716s\n",
      "1699it [06:24,  4.63it/s]\titers: 1700, epoch: 7 | loss: 0.3891699\n",
      "\tspeed: 0.2176s/iter; left time: 1238.9543s\n",
      "1799it [06:47,  4.39it/s]\titers: 1800, epoch: 7 | loss: 0.3701982\n",
      "\tspeed: 0.2247s/iter; left time: 1256.4911s\n",
      "1848it [06:58,  4.41it/s]\n",
      "Epoch: 7 cost time: 418.5943911075592\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:10,  8.65it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:11,  8.51it/s]\n",
      "Epoch: 7 | Train Loss: 0.4017612 Vali Loss: 0.7499416 Test Loss: 0.4163006 MAE Loss: 0.4233403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.250000000000004e-08\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:23,  4.46it/s]\titers: 100, epoch: 8 | loss: 0.3788587\n",
      "\tspeed: 1.7704s/iter; left time: 9639.6564s\n",
      "199it [00:46,  4.61it/s]\titers: 200, epoch: 8 | loss: 0.5553438\n",
      "\tspeed: 0.2277s/iter; left time: 1217.1707s\n",
      "299it [01:08,  3.83it/s]\titers: 300, epoch: 8 | loss: 0.5687422\n",
      "\tspeed: 0.2264s/iter; left time: 1187.2128s\n",
      "399it [01:31,  4.72it/s]\titers: 400, epoch: 8 | loss: 0.4443820\n",
      "\tspeed: 0.2257s/iter; left time: 1161.4229s\n",
      "499it [01:53,  4.54it/s]\titers: 500, epoch: 8 | loss: 0.4963173\n",
      "\tspeed: 0.2240s/iter; left time: 1129.9758s\n",
      "599it [02:16,  4.68it/s]\titers: 600, epoch: 8 | loss: 0.4265448\n",
      "\tspeed: 0.2231s/iter; left time: 1103.0839s\n",
      "699it [02:38,  4.61it/s]\titers: 700, epoch: 8 | loss: 0.5015807\n",
      "\tspeed: 0.2231s/iter; left time: 1081.1343s\n",
      "799it [03:01,  4.44it/s]\titers: 800, epoch: 8 | loss: 0.5460470\n",
      "\tspeed: 0.2271s/iter; left time: 1077.6298s\n",
      "899it [03:23,  4.61it/s]\titers: 900, epoch: 8 | loss: 0.4504886\n",
      "\tspeed: 0.2253s/iter; left time: 1046.4366s\n",
      "999it [03:46,  4.05it/s]\titers: 1000, epoch: 8 | loss: 0.5241756\n",
      "\tspeed: 0.2246s/iter; left time: 1020.8926s\n",
      "1099it [04:08,  4.71it/s]\titers: 1100, epoch: 8 | loss: 0.3676290\n",
      "\tspeed: 0.2269s/iter; left time: 1008.6098s\n",
      "1199it [04:30,  4.65it/s]\titers: 1200, epoch: 8 | loss: 0.5109408\n",
      "\tspeed: 0.2205s/iter; left time: 957.8704s\n",
      "1299it [04:53,  4.33it/s]\titers: 1300, epoch: 8 | loss: 0.5853857\n",
      "\tspeed: 0.2271s/iter; left time: 964.0133s\n",
      "1399it [05:16,  4.61it/s]\titers: 1400, epoch: 8 | loss: 0.3294960\n",
      "\tspeed: 0.2243s/iter; left time: 929.8386s\n",
      "1499it [05:39,  3.80it/s]\titers: 1500, epoch: 8 | loss: 0.4847545\n",
      "\tspeed: 0.2301s/iter; left time: 930.7429s\n",
      "1599it [06:01,  4.63it/s]\titers: 1600, epoch: 8 | loss: 0.3076046\n",
      "\tspeed: 0.2284s/iter; left time: 901.1522s\n",
      "1699it [06:24,  4.55it/s]\titers: 1700, epoch: 8 | loss: 0.4845665\n",
      "\tspeed: 0.2257s/iter; left time: 867.6353s\n",
      "1799it [06:47,  3.43it/s]\titers: 1800, epoch: 8 | loss: 0.3895288\n",
      "\tspeed: 0.2270s/iter; left time: 850.2425s\n",
      "1848it [06:59,  4.41it/s]\n",
      "Epoch: 8 cost time: 419.1231462955475\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:15,  8.06it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:17,  7.84it/s]\n",
      "Epoch: 8 | Train Loss: 0.4011904 Vali Loss: 0.7475238 Test Loss: 0.4155699 MAE Loss: 0.4227859\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.125000000000002e-08\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:23,  4.53it/s]\titers: 100, epoch: 9 | loss: 0.3719167\n",
      "\tspeed: 1.8907s/iter; left time: 6800.8463s\n",
      "199it [00:46,  4.63it/s]\titers: 200, epoch: 9 | loss: 0.3404319\n",
      "\tspeed: 0.2227s/iter; left time: 778.8630s\n",
      "299it [01:08,  4.59it/s]\titers: 300, epoch: 9 | loss: 0.3795159\n",
      "\tspeed: 0.2279s/iter; left time: 774.1273s\n",
      "399it [01:31,  4.07it/s]\titers: 400, epoch: 9 | loss: 0.4708918\n",
      "\tspeed: 0.2297s/iter; left time: 757.3968s\n",
      "499it [01:54,  4.56it/s]\titers: 500, epoch: 9 | loss: 0.3738245\n",
      "\tspeed: 0.2280s/iter; left time: 729.0282s\n",
      "599it [02:17,  4.49it/s]\titers: 600, epoch: 9 | loss: 0.4084910\n",
      "\tspeed: 0.2297s/iter; left time: 711.2930s\n",
      "699it [02:41,  4.02it/s]\titers: 700, epoch: 9 | loss: 0.2942807\n",
      "\tspeed: 0.2380s/iter; left time: 713.1871s\n",
      "799it [03:04,  4.58it/s]\titers: 800, epoch: 9 | loss: 0.4928238\n",
      "\tspeed: 0.2309s/iter; left time: 668.8957s\n",
      "899it [03:27,  4.51it/s]\titers: 900, epoch: 9 | loss: 0.3158938\n",
      "\tspeed: 0.2263s/iter; left time: 632.9573s\n",
      "999it [03:49,  4.47it/s]\titers: 1000, epoch: 9 | loss: 0.4570065\n",
      "\tspeed: 0.2236s/iter; left time: 603.0818s\n",
      "1099it [04:12,  4.76it/s]\titers: 1100, epoch: 9 | loss: 0.4537953\n",
      "\tspeed: 0.2241s/iter; left time: 581.9059s\n",
      "1199it [04:34,  4.58it/s]\titers: 1200, epoch: 9 | loss: 0.3645785\n",
      "\tspeed: 0.2234s/iter; left time: 557.7203s\n",
      "1299it [04:56,  4.07it/s]\titers: 1300, epoch: 9 | loss: 0.3160651\n",
      "\tspeed: 0.2251s/iter; left time: 539.5616s\n",
      "1399it [05:19,  4.67it/s]\titers: 1400, epoch: 9 | loss: 0.3304859\n",
      "\tspeed: 0.2250s/iter; left time: 516.8271s\n",
      "1499it [05:41,  4.08it/s]\titers: 1500, epoch: 9 | loss: 0.4103331\n",
      "\tspeed: 0.2235s/iter; left time: 491.0897s\n",
      "1599it [06:04,  4.26it/s]\titers: 1600, epoch: 9 | loss: 0.3515675\n",
      "\tspeed: 0.2257s/iter; left time: 473.2294s\n",
      "1699it [06:26,  4.53it/s]\titers: 1700, epoch: 9 | loss: 0.3989633\n",
      "\tspeed: 0.2216s/iter; left time: 442.5831s\n",
      "1799it [06:49,  4.18it/s]\titers: 1800, epoch: 9 | loss: 0.6767653\n",
      "\tspeed: 0.2331s/iter; left time: 442.1828s\n",
      "1848it [07:00,  4.39it/s]\n",
      "Epoch: 9 cost time: 420.9385962486267\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:09,  8.76it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:10,  8.58it/s]\n",
      "Epoch: 9 | Train Loss: 0.4011515 Vali Loss: 0.7517159 Test Loss: 0.4164327 MAE Loss: 0.4234101\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.562500000000001e-08\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "99it [00:23,  4.59it/s]\titers: 100, epoch: 10 | loss: 0.4051618\n",
      "\tspeed: 1.7496s/iter; left time: 3060.1196s\n",
      "199it [00:46,  4.31it/s]\titers: 200, epoch: 10 | loss: 0.2857614\n",
      "\tspeed: 0.2277s/iter; left time: 375.4974s\n",
      "299it [01:08,  4.59it/s]\titers: 300, epoch: 10 | loss: 0.3101243\n",
      "\tspeed: 0.2222s/iter; left time: 344.1321s\n",
      "399it [01:30,  4.58it/s]\titers: 400, epoch: 10 | loss: 0.3723844\n",
      "\tspeed: 0.2243s/iter; left time: 324.9803s\n",
      "499it [01:53,  4.45it/s]\titers: 500, epoch: 10 | loss: 0.2747294\n",
      "\tspeed: 0.2304s/iter; left time: 310.8534s\n",
      "599it [02:16,  4.33it/s]\titers: 600, epoch: 10 | loss: 0.2873923\n",
      "\tspeed: 0.2274s/iter; left time: 283.9756s\n",
      "699it [02:39,  4.41it/s]\titers: 700, epoch: 10 | loss: 0.3550046\n",
      "\tspeed: 0.2298s/iter; left time: 264.0889s\n",
      "799it [03:02,  4.58it/s]\titers: 800, epoch: 10 | loss: 0.5214928\n",
      "\tspeed: 0.2274s/iter; left time: 238.5566s\n",
      "899it [03:24,  4.60it/s]\titers: 900, epoch: 10 | loss: 0.4760993\n",
      "\tspeed: 0.2218s/iter; left time: 210.5193s\n",
      "999it [03:47,  3.87it/s]\titers: 1000, epoch: 10 | loss: 0.4977808\n",
      "\tspeed: 0.2295s/iter; left time: 194.8222s\n",
      "1099it [04:11,  4.01it/s]\titers: 1100, epoch: 10 | loss: 0.5953159\n",
      "\tspeed: 0.2408s/iter; left time: 180.3408s\n",
      "1199it [04:34,  4.55it/s]\titers: 1200, epoch: 10 | loss: 0.3554712\n",
      "\tspeed: 0.2341s/iter; left time: 151.9096s\n",
      "1299it [04:57,  4.13it/s]\titers: 1300, epoch: 10 | loss: 0.4268078\n",
      "\tspeed: 0.2300s/iter; left time: 126.2502s\n",
      "1399it [05:24,  4.01it/s]\titers: 1400, epoch: 10 | loss: 0.6089658\n",
      "\tspeed: 0.2628s/iter; left time: 117.9975s\n",
      "1499it [05:49,  4.41it/s]\titers: 1500, epoch: 10 | loss: 0.4389871\n",
      "\tspeed: 0.2584s/iter; left time: 90.1767s\n",
      "1599it [06:12,  4.76it/s]\titers: 1600, epoch: 10 | loss: 0.3727269\n",
      "\tspeed: 0.2238s/iter; left time: 55.7231s\n",
      "1699it [06:35,  4.30it/s]\titers: 1700, epoch: 10 | loss: 0.4292260\n",
      "\tspeed: 0.2275s/iter; left time: 33.8917s\n",
      "1799it [06:57,  3.84it/s]\titers: 1800, epoch: 10 | loss: 0.4725687\n",
      "\tspeed: 0.2263s/iter; left time: 11.0864s\n",
      "1848it [07:09,  4.31it/s]\n",
      "Epoch: 10 cost time: 429.1273446083069\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:08,  8.85it/s]\n",
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "609it [01:10,  8.69it/s]\n",
      "Epoch: 10 | Train Loss: 0.4009504 Vali Loss: 0.7475744 Test Loss: 0.4154129 MAE Loss: 0.4226615\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.812500000000005e-09\n",
      "success delete checkpoints\n"
     ]
    }
   ],
   "source": [
    "!python /workspace/Time-LLM/run_main.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --model_id ETTh1_96_96 \\\n",
    "  --model_comment \"colab test\" \\\n",
    "  --model TimeLLM \\\n",
    "  --data ETTh1 \\\n",
    "  --root_path /workspace/dataset/dataset/ETT-small/\\\n",
    "  --data_path ETTh1.csv \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --llm_model Gemma2b \\\n",
    "  --llm_dim 2048\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
